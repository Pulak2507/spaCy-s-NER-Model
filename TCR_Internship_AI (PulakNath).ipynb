{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VQxeMvVNdLTq"
      },
      "outputs": [],
      "source": [
        "#NAME: PULAK NATH\n",
        "#CERTIFICATION CODE: TCRIL01R16\n",
        "#EMAIL: nathpulak48002507@gmail.com\n",
        "#BATCH: ARTIFICIAL INTELLIGENCE\n",
        "#ASSIGNMENT - DEEP LEARNING\n",
        "#PROJECT NAME- DETERMINING DIFFERENT ENTITY IN FOOD DELIVERY DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "jV43fSswgj6S",
        "outputId": "271a338c-c24f-4618-f703-f0b8c3843cbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy==2.3.1\n",
            "  Downloading spacy-2.3.1-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.1) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.1) (2.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.1) (4.64.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.1) (0.10.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.1) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.1) (1.21.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.1) (2.23.0)\n",
            "Collecting thinc==7.4.1\n",
            "  Downloading thinc-7.4.1-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 34.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.1) (3.0.7)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.3.1) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.1) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.1) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.1) (2022.6.15)\n",
            "Installing collected packages: thinc, spacy\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.4.0 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.3.1 which is incompatible.\n",
            "en-core-web-lg 3.4.0 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.3.1 which is incompatible.\u001b[0m\n",
            "Successfully installed spacy-2.3.1 thinc-7.4.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "spacy",
                  "thinc"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# downloading spacy language model\n",
        "!pip install spacy==2.3.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUK9XaSBhI1u",
        "outputId": "8ec20403-2abc-47ba-e149-e43500b04105"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (3.4.0) requires spaCy v3.4 and is incompatible with the current spaCy version (2.3.1). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ],
      "source": [
        "# importing libraries\n",
        "import en_core_web_sm\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "import spacy\n",
        "from spacy.util import minibatch, compounding\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nuPyMWZJ_KF-"
      },
      "outputs": [],
      "source": [
        "# Generating Food Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a5u7UFGTjdT8"
      },
      "outputs": [],
      "source": [
        "# USDA's Branded Food's dataset: \n",
        "#https://fdc.nal.usda.gov/fdc-datasets/FoodData_Central_foundation_food_csv_2022-04-28.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VN61KvoK_Nr5"
      },
      "outputs": [],
      "source": [
        "# Preparing the food data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "mv_Vp5tJhJwd",
        "outputId": "bd1475e7-62b0-4efa-8db6-9cc1353e104c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-00e8936e-36aa-4350-8f24-68b4e1c76d4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fdc_id</th>\n",
              "      <th>data_type</th>\n",
              "      <th>description</th>\n",
              "      <th>food_category_id</th>\n",
              "      <th>publication_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1105904</td>\n",
              "      <td>branded_food</td>\n",
              "      <td>WESSON Vegetable Oil 1 GAL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-11-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1105905</td>\n",
              "      <td>branded_food</td>\n",
              "      <td>SWANSON BROTH BEEF</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-11-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1105906</td>\n",
              "      <td>branded_food</td>\n",
              "      <td>CAMPBELL'S SLOW KETTLE SOUP CLAM CHOWDER</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-11-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1105907</td>\n",
              "      <td>branded_food</td>\n",
              "      <td>CAMPBELL'S SLOW KETTLE SOUP CHEESE BROCCOLI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-11-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1105908</td>\n",
              "      <td>branded_food</td>\n",
              "      <td>SWANSON BROTH CHICKEN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-11-13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00e8936e-36aa-4350-8f24-68b4e1c76d4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-00e8936e-36aa-4350-8f24-68b4e1c76d4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-00e8936e-36aa-4350-8f24-68b4e1c76d4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    fdc_id     data_type                                  description  \\\n",
              "0  1105904  branded_food                   WESSON Vegetable Oil 1 GAL   \n",
              "1  1105905  branded_food                           SWANSON BROTH BEEF   \n",
              "2  1105906  branded_food     CAMPBELL'S SLOW KETTLE SOUP CLAM CHOWDER   \n",
              "3  1105907  branded_food  CAMPBELL'S SLOW KETTLE SOUP CHEESE BROCCOLI   \n",
              "4  1105908  branded_food                        SWANSON BROTH CHICKEN   \n",
              "\n",
              "   food_category_id publication_date  \n",
              "0               NaN       2020-11-13  \n",
              "1               NaN       2020-11-13  \n",
              "2               NaN       2020-11-13  \n",
              "3               NaN       2020-11-13  \n",
              "4               NaN       2020-11-13  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# read in the food csv file\n",
        "food_df = pd.read_csv(\"/content/drive/MyDrive/INTERNSHIPS/TCR Internship (AI)/Final Project/food.csv\")\n",
        "\n",
        "# print row and column information\n",
        "food_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1XFHzCojOpx",
        "outputId": "48433e73-2a25-46d7-c8ce-ae99114590aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1142610"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print the size \n",
        "food_df[\"description\"].size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGu8f5YVjSN4",
        "outputId": "3937b187-9980-4004-966e-a58e72de4abf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "40508"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# disqualify foods with special characters, lowercase and extract results from \"description\" column\n",
        "foods = food_df[food_df[\"description\"].str.contains(\"[^a-zA-Z ]\") == False][\"description\"].apply(lambda food: food.lower())\n",
        "\n",
        "# filter out foods with more than 3 words, drop any duplicates\n",
        "foods = foods[foods.str.split().apply(len) <= 3].drop_duplicates()\n",
        "\n",
        "# print the remaining size\n",
        "foods.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "BWqL_KkCjqTY",
        "outputId": "519ede75-9184-4197-862d-3018bcb14886"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnAAAAGDCAYAAACr/S2JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZRlZX3u8e8jgwOKoBCvDNqIGEUTUZHBKcQBEQdIVCJRQSWgCThcNZHkeoU4RIzXmGiUdTG2YC6KxCEQxSDigKICDSKCSuiLICBCa4ONEwr87h/7reumqKqubjhV/Tbfz1pnnb3fPf121VldT7/v3menqpAkSVI/7rLYBUiSJGnNGOAkSZI6Y4CTJEnqjAFOkiSpMwY4SZKkzhjgJEmSOmOAkzQvSY5N8tZFOnaSfCjJdUnOXowaptVTSR68htu8MMnnJlXT7ZXkJUm+ukDHemKSi+dY/oAkP0uywULUI/XIACd1KsllSa5Nssmo7c+SfGkRy5qUJwBPA7apql3GC5Js2P7Y7zpqe2ELWdPbvrdwJd9aVR1fVXuuzbZJjkzym3aeU6+/uqNrnOP4S9rP82fTXn8yz+1vFXir6itV9buj5Zcleepo+Q+q6p5VdfMdeybS+sMAJ/VtA+DVi13EmlqLnpUHApdV1c+nL6iqm4CvA08aNT8J+N4MbWesYZ0brmGdk/SxFmqmXn+/CDVsNq2Gjy1CDZIwwEm9eyfw+iSbTV8w6jXZcNT2pSR/1qZfkuTMJO9Ocn2SS5M8rrVf0Xr3Dpy22y2SnJbkhiRfTvLA0b4f2patTHJxkv1Gy45NcnSSU5L8HPjDGerdKsnJbfvlSQ5u7QcB/wLs3np9/naGn8MZ3DqsPRF4xwxtZ7R9HtyOsbIdc6tRHZXk0CSXAJe0tr9McnWSHyZ52bS6907ynfYzuSrJ62eo7zZDlO04r0hySfv5vy9JZtp2Lkmek+Sito8vJXnYaNnDWtv1bZ3njJbdt537qjYsvf2aHnu0r2Nb/Z9pP4ezkmzflk2F5m9N9dol2SPJlW35vwIPAP5jqmdx+mc3yb2TfLD9Dq5K8tap/wQkeXD7LP40yY+TGCp1p2CAk/q2DPgSMGNomIddgQuA+wIfAU4AHgs8GHgR8M9J7jla/4XAW4AtgPOB4wEyDOOe1vbxO8ALgPcn2XG07Z8CbwPuBcx0rdUJwJXAVsDzgL9L8uSq+iDwCuDrrdfniBm2PQN4fJK7JNkC2AQ4Edhl1PYw4IwkTwbeDuwH3B+4vB17bN/2s9kxyV4MP9+nATsAT5227geBl1fVvYBHAF+Yob7ZPIvh5/37rZ6nr8G2JHkI8FHgNcCWwCkMQWjjJBsB/wF8juF38krg+CRTQ5fvA37F8DN4WXvdHi8A/hbYHFjO8LumqqZC9CNn6rWrqhcDPwCePUfP4rHATQyfy0cBewJ/1pa9pZ3j5sA2wHtv53lIXTDASf17E/DKJFuuxbbfr6oPtWuNPgZsC7y5qm6sqs8Bv2b4oznlM1V1RlXdCPwPhl6xbRmCyGVtXzdV1TeBTwDPH217UlWdWVW3VNWvxkW0fTweeENV/aqqzmfodTtgnudxFnAP4PcYetq+WlW/AL4/arusqn7AEEKXVtV57Tz+up3HktH+3l5VK6vqlwzB6kNVdWEbwj1y2rF/wxD0Nq2q66rqvHnWDHBUVV3f6voisNMc6+7XetKmXlsBf8LwOzmtqn4D/C/g7sDjgN2Ae7Zj/LqqvgB8Gti/9V49F3hTVf28qi4EjptHvT+eVsPDRss+VVVntyHt41dzLvOW5H7A3sBrWq3XAu9mCIww/PwfCGzVPjsLciOGtNgMcFLn2h/fTwOHr8Xm14ymf9n2N71t3AN3xei4PwNWMvSYPRDYdfzHnSEo/beZtp3BVsDKqrph1HY5sPV8TqIFwrMZhkyfBHylLfrqqG1qKG+rtu/xefxk2rHGtW41bf5ybu25DAHj8jaUt/t8am5+NJr+Bbf+WU93YlVtNnr9kNueyy2t1q2n6m5t49q3Zuit23A15zWTLabV8N21PJc18UBgI+Dq0WfrfzP0KgL8FRDg7DZMfHt7EqUurEsX6Epae0cA5wHvGrVNXfB/D2BVmx4HqrWx7dREG1q9D/BDhiDw5ap62hzb1hzLfgjcJ8m9RiHuAcBVa1Db1HVw2zH03sEQ5F7U2o4eHWt87d4mDEPI42ONa72a0Xm3un67YtU5wD5tyPIwhqHb8fqT9EOGHkZg+LqVduyrgJuBbZPcZRTiHgD8F7CCYUhyW4abPaaWLZa5PhtXADcyhMebbrNh1Y+AqeslnwB8PskZVbV8IpVK6wh74KT1QPtj9THgVaO2FQx/yF+UZIPWM7HWF6o3eyd5QpKNGa49+kZVXcHQA/iQJC9OslF7PXbaENtc9V8BfA14e5K7Jfl94CDg/6xBbWcw3ByxLfCd1nYmsAfDcN5UD9xHgZcm2SnJXYG/A86qqstm2e+JwEuS7JjkHgxhGYB2rdkLk9y7DWGuAm6ZZT+TcCLwzCRPaQHydQxh52sMw8q/AP6q/T72AJ4NnNCGzD8JHJnkHu1axek3rNyRrgEetDbLq+pqhmvc3pVk03ZN4/ZJ/gAgyfOTbNNWv44hDC7k70BaFAY4af3xZoaL98cOBv6SYYjw4Qx/2G+PjzAEmJXAYxh6t2i9ZnsyXJf0Q4bhtHcAd12Dfe8PLGnbfwo4oqo+vwbbfw24N0MYq1bXjxl6m66tqkta2+eB/8lwjd7VDKH2BTPucVj/s8A/MtycsJzb3qTwYuCyJKsYbrZ44RrUfLtU1cUMv4P3Aj9mCGjPbte8/brNP6Mtez9wQFVN9bgdxjDM+SOGmwQ+NI9DXp9bfw/ca+dZ6pHAcW0IdL8Zlr8deGNbPtMNOQcAGzME8+uAjzPcfAHDTSBnJfkZcDLw6qq6dJ51Sd1K+3dOkiRJnbAHTpIkqTMGOEmSpM4Y4CRJkjpjgJMkSeqMAU6SJKkzd7ov8t1iiy1qyZIli12GJEnSap177rk/rqrbPCrxThfglixZwrJlyxa7DEmSpNVKMuNj7hxClSRJ6owBTpIkqTMGOEmSpM4Y4CRJkjpjgJMkSeqMAU6SJKkzBjhJkqTOGOAkSZI6Y4CTJEnqjAFOkiSpMwY4SZKkzhjgJEmSOmOAkyRJ6syGi12AJEkLbcnhn1nsEtS5y4565qIe3x44SZKkzhjgJEmSOjOxAJdk2yRfTPKdJBcleXVrPzLJVUnOb6+9R9v8dZLlSS5O8vRR+16tbXmSw0ft2yU5q7V/LMnGkzofSZKkdcUke+BuAl5XVTsCuwGHJtmxLXt3Ve3UXqcAtGUvAB4O7AW8P8kGSTYA3gc8A9gR2H+0n3e0fT0YuA44aILnI0mStE6YWICrqqur6rw2fQPwXWDrOTbZBzihqm6squ8Dy4Fd2mt5VV1aVb8GTgD2SRLgycDH2/bHAftO5mwkSZLWHQtyDVySJcCjgLNa02FJLkiyNMnmrW1r4IrRZle2ttna7wtcX1U3TWuXJElar008wCW5J/AJ4DVVtQo4Gtge2Am4GnjXAtRwSJJlSZatWLFi0oeTJEmaqIkGuCQbMYS346vqkwBVdU1V3VxVtwAfYBgiBbgK2Ha0+Tatbbb2nwCbJdlwWvttVNUxVbVzVe285ZZb3jEnJ0mStEgmeRdqgA8C362qfxi133+02h8BF7bpk4EXJLlrku2AHYCzgXOAHdodpxsz3OhwclUV8EXgeW37A4GTJnU+kiRJ64pJPonh8cCLgW8nOb+1/Q3DXaQ7AQVcBrwcoKouSnIi8B2GO1gPraqbAZIcBpwKbAAsraqL2v7eAJyQ5K3ANxkCoyRJ0nptYgGuqr4KZIZFp8yxzduAt83QfspM21XVpfx2CFaSJOlOwScxSJIkdcYAJ0mS1BkDnCRJUmcMcJIkSZ0xwEmSJHXGACdJktQZA5wkSVJnDHCSJEmdMcBJkiR1xgAnSZLUGQOcJElSZwxwkiRJnTHASZIkdcYAJ0mS1BkDnCRJUmcMcJIkSZ0xwEmSJHXGACdJktQZA5wkSVJnDHCSJEmdMcBJkiR1xgAnSZLUGQOcJElSZwxwkiRJnTHASZIkdcYAJ0mS1BkDnCRJUmcMcJIkSZ0xwEmSJHXGACdJktQZA5wkSVJnDHCSJEmdMcBJkiR1xgAnSZLUGQOcJElSZwxwkiRJnTHASZIkdcYAJ0mS1BkDnCRJUmcMcJIkSZ0xwEmSJHXGACdJktQZA5wkSVJnDHCSJEmdMcBJkiR1xgAnSZLUGQOcJElSZwxwkiRJnTHASZIkdcYAJ0mS1BkDnCRJUmcMcJIkSZ2ZWIBLsm2SLyb5TpKLkry6td8nyWlJLmnvm7f2JHlPkuVJLkjy6NG+DmzrX5LkwFH7Y5J8u23zniSZ1PlIkiStKybZA3cT8Lqq2hHYDTg0yY7A4cDpVbUDcHqbB3gGsEN7HQIcDUPgA44AdgV2AY6YCn1tnYNH2+01wfORJElaJ0wswFXV1VV1Xpu+AfgusDWwD3BcW+04YN82vQ/w4Rp8A9gsyf2BpwOnVdXKqroOOA3Yqy3btKq+UVUFfHi0L0mSpPXWglwDl2QJ8CjgLOB+VXV1W/Qj4H5temvgitFmV7a2udqvnKF9puMfkmRZkmUrVqy4XeciSZK02CYe4JLcE/gE8JqqWjVe1nrOatI1VNUxVbVzVe285ZZbTvpwkiRJEzXRAJdkI4bwdnxVfbI1X9OGP2nv17b2q4BtR5tv09rmat9mhnZJkqT12iTvQg3wQeC7VfUPo0UnA1N3kh4InDRqP6Ddjbob8NM21HoqsGeSzdvNC3sCp7Zlq5Ls1o51wGhfkiRJ660NJ7jvxwMvBr6d5PzW9jfAUcCJSQ4CLgf2a8tOAfYGlgO/AF4KUFUrk7wFOKet9+aqWtmm/wI4Frg78Nn2kiRJWq9NLMBV1VeB2b6X7SkzrF/AobPsaymwdIb2ZcAjbkeZkiRJ3fFJDJIkSZ0xwEmSJHXGACdJktQZA5wkSVJnDHCSJEmdMcBJkiR1xgAnSZLUGQOcJElSZwxwkiRJnTHASZIkdcYAJ0mS1BkDnCRJUmcMcJIkSZ0xwEmSJHXGACdJktQZA5wkSVJnDHCSJEmdMcBJkiR1xgAnSZLUGQOcJElSZwxwkiRJnTHASZIkdcYAJ0mS1BkDnCRJUmcMcJIkSZ0xwEmSJHXGACdJktQZA5wkSVJnDHCSJEmdMcBJkiR1xgAnSZLUGQOcJElSZwxwkiRJnTHASZIkdcYAJ0mS1BkDnCRJUmcMcJIkSZ0xwEmSJHXGACdJktQZA5wkSVJnDHCSJEmdMcBJkiR1xgAnSZLUGQOcJElSZ1Yb4JK8OsmmGXwwyXlJ9lyI4iRJknRb8+mBe1lVrQL2BDYHXgwcNdGqJEmSNKv5BLi0972Bf62qi0ZtkiRJWmDzCXDnJvkcQ4A7Ncm9gFsmW5YkSZJms+E81jkI2Am4tKp+keS+wEsnW5YkSZJmM58euAJ2BF7V5jcB7jaxiiRJkjSn+QS49wO7A/u3+RuA902sIkmSJM1pPkOou1bVo5N8E6Cqrkuy8YTrkiRJ0izm0wP3myQbMAylkmRL5nETQ5KlSa5NcuGo7cgkVyU5v732Hi376yTLk1yc5Omj9r1a2/Ikh4/at0tyVmv/mKFSkiTdWcwnwL0H+BTwO0neBnwV+Lt5bHcssNcM7e+uqp3a6xSAJDsCLwAe3rZ5f5INWnB8H/AMhuvw9m/rAryj7evBwHUMN1tIkiSt91Y7hFpVxyc5F3gKw/e/7VtV353HdmckWTLPOvYBTqiqG4HvJ1kO7NKWLa+qSwGSnADsk+S7wJOBP23rHAccCRw9z+NJkiR1a9YeuCSbtvf7ANcCHwU+AlzT2tbWYUkuaEOsm7e2rYErRutc2dpma78vcH1V3TStfbZzOSTJsiTLVqxYcTtKlyRJWnxzDaF+pL2fCywbvabm18bRwPYM3yt3NfCutdzPGqmqY6pq56raecstt1yIQ0qSJE3MrEOoVfWs9r7dHXWwqrpmajrJB4BPt9mrgG1Hq27T2pil/SfAZkk2bL1w4/UlSZLWa6u9iSHJ6fNpm48k9x/N/hEwdYfqycALktw1yXbADsDZwDnADu2O040ZbnQ4uaoK+CLwvLb9gcBJa1OTJElSb2btgUtyN+AewBbtWrWpB9hvyhzXm422/yiwR9v+SuAIYI8kOzF8JcllwMsBquqiJCcC3wFuAg6tqpvbfg4DTgU2AJZW1UXtEG8ATkjyVuCbwAfnf9qSJEn9musu1JcDrwG2As4bta8C/nl1O66q/WdonjVkVdXbgLfN0H4KcMoM7Zfy2ztVJUmS7jTmugbun4B/SvLKqnrvAtYkSZKkOcw1hPrkqvoCcFWSP56+vKo+OdHKJEmSNKO5hlD/APgC8OwZlhVggJMkSVoEcw2hHtEm31xV3x8va3eKSpIkaRHM51mon5ih7eN3dCGSJEman7mugXsow8Pl7z3tGrhNgbtNujBJkiTNbK5r4H4XeBawGbe+Du4G4OBJFiVJkqTZzXUN3EnASUl2r6qvL2BNkiRJmsNcPXBTlif5G2DJeP2qetmkipIkSdLs5hPgTgK+AnweuHmy5UiSJGl15hPg7lFVb5h4JZIkSZqX+QS4TyfZuz2TVNKd0JLDP7PYJahzlx31zMUuQVqvzOd74F7NEOJ+mWRVkhuSrJp0YZIkSZrZanvgqupeC1GIJEmS5mfWHrgkLxpNP37assMmWZQkSZJmN9cQ6mtH0++dtsyvEJEkSVokcwW4zDI907wkSZIWyFwBrmaZnmlekiRJC2SumxgemuQCht627ds0bf5BE69MkiRJM5orwD1swaqQJEnSvM31MPvLF7IQSZIkzc98vshXkiRJ6xADnCRJUmcMcJIkSZ2Z9Rq4JN9mjq8Lqarfn0hFkiRJmtNcd6E+q70f2t7/tb2/cHLlSJIkaXVWexdqkqdV1aNGiw5Pch5w+KSLkyRJ0m3N5xq4jB9mn+Rx89xOkiRJEzDXEOqUg4ClSe7N8BSG6/Bh9pIkSYtmtQGuqs4FHtkCHFX104lXJUmSpFmtdig0yb2T/ANwOnB6kndNhTlJkiQtvPlcy7YUuAHYr71WAR+aZFGSJEma3Xyugdu+qp47mv/bJOdPqiBJkiTNbT49cL9M8oSpmXZH6i8nV5IkSZLmMp8euD8HjhvdhboSOHCiVUmSJGlW87kL9XyGu1A3bfOrJl6VJEmSZrUmd6F+AfiCd6FKkiQtLu9ClSRJ6ox3oUqSJHXGu1AlSZI6M58euFcAHx5d93Yd3oUqSZK0aGYNcEkeUFU/qKpv4V2okiRJ64y5hlD/fWoiySeqapXhTZIkafHNFeAymn7QpAuRJEnS/MwV4GqWaUmSJC2iuW5ieGSSVQw9cXdv07T5qqpNJ16dJEmSbmPWAFdVGyxkIZIkSZqf+XwPnCRJktYhBjhJkqTOGOAkSZI6Y4CTJEnqjAFOkiSpMxMLcEmWJrk2yYWjtvskOS3JJe1989aeJO9JsjzJBUkePdrmwLb+JUkOHLU/Jsm32zbvSRIkSZLuBCbZA3cssNe0tsOB06tqB+D0Ng/wDGCH9joEOBqGwAccAewK7AIcMRX62joHj7abfixJkqT10sQCXFWdAayc1rwPcFybPg7Yd9T+4Rp8A9gsyf2BpwOnVdXKqroOOA3Yqy3btKq+UVUFfHi0L0mSpPXaQl8Dd7+qurpN/wi4X5veGrhitN6VrW2u9itnaJ9RkkOSLEuybMWKFbfvDCRJkhbZot3E0HrOFuQZq1V1TFXtXFU7b7nllgtxSEmSpIlZ6AB3TRv+pL1f29qvArYdrbdNa5urfZsZ2iVJktZ7Cx3gTgam7iQ9EDhp1H5Auxt1N+Cnbaj1VGDPJJu3mxf2BE5ty1Yl2a3dfXrAaF+SJEnrtVkfZn97JfkosAewRZIrGe4mPQo4MclBwOXAfm31U4C9geXAL4CXAlTVyiRvAc5p6725qqZujPgLhjtd7w58tr0kSZLWexMLcFW1/yyLnjLDugUcOst+lgJLZ2hfBjzi9tQoSZLUI5/EIEmS1BkDnCRJUmcMcJIkSZ0xwEmSJHXGACdJktQZA5wkSVJnDHCSJEmdMcBJkiR1xgAnSZLUGQOcJElSZwxwkiRJnTHASZIkdcYAJ0mS1BkDnCRJUmcMcJIkSZ0xwEmSJHXGACdJktQZA5wkSVJnDHCSJEmdMcBJkiR1xgAnSZLUGQOcJElSZwxwkiRJnTHASZIkdcYAJ0mS1BkDnCRJUmcMcJIkSZ0xwEmSJHXGACdJktQZA5wkSVJnDHCSJEmdMcBJkiR1xgAnSZLUGQOcJElSZwxwkiRJnTHASZIkdcYAJ0mS1BkDnCRJUmcMcJIkSZ0xwEmSJHXGACdJktQZA5wkSVJnDHCSJEmdMcBJkiR1xgAnSZLUGQOcJElSZwxwkiRJnTHASZIkdcYAJ0mS1BkDnCRJUmcMcJIkSZ0xwEmSJHVmUQJcksuSfDvJ+UmWtbb7JDktySXtffPWniTvSbI8yQVJHj3az4Ft/UuSHLgY5yJJkrTQFrMH7g+raqeq2rnNHw6cXlU7AKe3eYBnADu01yHA0TAEPuAIYFdgF+CIqdAnSZK0PluXhlD3AY5r08cB+47aP1yDbwCbJbk/8HTgtKpaWVXXAacBey100ZIkSQttsQJcAZ9Lcm6SQ1rb/arq6jb9I+B+bXpr4IrRtle2ttnabyPJIUmWJVm2YsWKO+ocJEmSFsWGi3TcJ1TVVUl+BzgtyffGC6uqktQddbCqOgY4BmDnnXe+w/YrSZK0GBalB66qrmrv1wKfYriG7Zo2NEp7v7atfhWw7WjzbVrbbO2SJEnrtQUPcEk2SXKvqWlgT+BC4GRg6k7SA4GT2vTJwAHtbtTdgJ+2odZTgT2TbN5uXtiztUmSJK3XFmMI9X7Ap5JMHf8jVfWfSc4BTkxyEHA5sF9b/xRgb2A58AvgpQBVtTLJW4Bz2npvrqqVC3cakiRJi2PBA1xVXQo8cob2nwBPmaG9gENn2ddSYOkdXaMkSdK6bF36GhFJkiTNgwFOkiSpMwY4SZKkzhjgJEmSOmOAkyRJ6owBTpIkqTMGOEmSpM4Y4CRJkjpjgJMkSeqMAU6SJKkzBjhJkqTOGOAkSZI6Y4CTJEnqjAFOkiSpMwY4SZKkzhjgJEmSOmOAkyRJ6owBTpIkqTMGOEmSpM4Y4CRJkjpjgJMkSeqMAU6SJKkzBjhJkqTOGOAkSZI6Y4CTJEnqjAFOkiSpMwY4SZKkzhjgJEmSOmOAkyRJ6owBTpIkqTMGOEmSpM4Y4CRJkjpjgJMkSeqMAU6SJKkzBjhJkqTOGOAkSZI6Y4CTJEnqjAFOkiSpMxsudgHroyWHf2axS1DnLjvqmYtdgiRpHWYPnCRJUmcMcJIkSZ0xwEmSJHXGACdJktQZA5wkSVJnDHCSJEmdMcBJkiR1xgAnSZLUGQOcJElSZwxwkiRJnTHASZIkdcYAJ0mS1JnuA1ySvZJcnGR5ksMXux5JkqRJ6zrAJdkAeB/wDGBHYP8kOy5uVZIkSZPVdYADdgGWV9WlVfVr4ARgn0WuSZIkaaJ6D3BbA1eM5q9sbZIkSeutDRe7gIWQ5BDgkDb7syQXL2Y9AmAL4MeLXcS6Ku9Y7Aq0FvxMz8HPdJf8TM9hAT/TD5ypsfcAdxWw7Wh+m9Z2K1V1DHDMQhWl1UuyrKp2Xuw6pDuKn2mtb/xMr9t6H0I9B9ghyXZJNgZeAJy8yDVJkiRNVNc9cFV1U5LDgFOBDYClVXXRIpclSZI0UV0HOICqOgU4ZbHr0BpzSFvrGz/TWt/4mV6HpaoWuwZJkiStgd6vgZMkSbrTMcBJ0mok2SzJXyx2HdLaGn+Gk+yR5NOLXZNuHwOcJK3eZoABTj1b489we1yl1lEGOE1EktcmubC9XpNkSZLvJvlAkouSfC7J3du62yf5zyTnJvlKkocudv3SNEcB2yc5P8mHkjwHIMmnkixt0y9L8rY2favP/yLWLU35/59h4J3APZN8PMn3khyfJABJLkvyjiTnAc9PsmeSryc5L8m/JblnW+8xSb7c/t0+Ncn9F+/U7pwMcLrDJXkM8FJgV2A34GBgc2AH4H1V9XDgeuC5bZNjgFdW1WOA1wPvX/CipbkdDvzfqtqJ4WuLntjatwZ2bNNPBM6Y6fOf5FELXK803fgz/JfAo4DXMHx+HwQ8frTuT6rq0cDngTcCT23zy4DXJtkIeC/wvPbv9lLgbQt2JgLWg68R0TrpCcCnqurnAEk+yfDH7ftVdX5b51xgSfvf3OOAf2v/AQS46wLXK62JrwCvSbIj8B1g89b7sDvwKuBlzPz5/+Yi1SvN5OyquhKg9cotAb7aln2sve/GEPDObP8+bwx8Hfhd4BHAaa19A+DqhSpcAwOcFtKNo+mbgbsz9AJf3/5XKK3zquqqJJsBewFnAPcB9gN+VlU3jP4jIq3Lpv97PM4DP2/vAU6rqv3HGyb5PeCiqtp9siVqLg6hahK+Auyb5B5JNgH+qLXdRlWtAr6f5PkAGTxy4UqV5uUG4F6j+W8wDD+dwfDZfj2//YzP+/MvLaDpn+H5+Abw+CQPBkiySZKHABcDWybZvbVvlOThd2i1Wi174HSHq6rzkhwLnN2a/gW4bo5NXggcneSNwEbACcC3JlqktAaq6idJzkxyIfBZhkC2Z1UtT3I5Qy/cV9q6t/n8V5XDp1pU0z7DvwSumcc2K5K8BPhokqlLW95YVf+V5HnAe5LcmyFL/CPgoywXkE9ikCRJ6oxDqJIkSZ0xwEmSJHXGACdJktQZA5wkSVJnDHCSJEmdMcBJWmclqSTvGs2/PsmRd9C+j21fhTBRSZ7fngP8xWntn0qy72j+4vZVOlPzn0jyx2t5zJck+ee1r1rSus4AJ2lddiPwx0m2WOxCxpKsyXdoHgQcXFV/OK39TIbHyJHkvgzffj/+Zvvdga/Ns54N1qAeSesBA5ykddlNwDHAf5++YHoPWpKftfc9knw5yUlJLk1yVJIXJjk7ybeTbEl8mxYAAAL5SURBVD/azVOTLEvyX0me1bbfIMk7k5yT5IIkLx/t9ytJTmZ4Bur0evZv+78wyTta25sYng38wSTvnLbJ12gBrr3/B8O32yfJdsAvq+pHM+136nyTvCvJt4Ddk7y0ncfZjB5M3noAL0zyrSRnzO/HLmld55MYJK3r3gdckOTv12CbRwIPA1YClzI8DWGXJK8GXsnwGCwYHuC9C7A98MX2yKADgJ9W1WPbt8+fmeRzbf1HA4+oqu+PD5ZkK+AdwGMYnjryuST7VtWbkzwZeH1VLZtW47nAI5JszBDgvgw8qNX9KOBrc+z334FNgLOq6nVJ7g98pK33U+CLwNTTH94EPH30DFdJ6wF74CSt09rzcj8MvGoNNjunqq6uqhuB/wtMBbBvM4S2KSdW1S1VdQlD0HsosCdwQJLzgbOA+wI7tPXPnh7emscCX6qqFVV1E3A88KTVnNeNDI8eejSwWzvW1xnC3OMYhljn2u/NwCfa9K6j9X4NfGx0qDOBY5McDDjUKq0nDHCSevCPDNeSbTJqu4n2b1iSuwAbj5bdOJq+ZTR/C7ceeZj+LMECAryyqnZqr+2qaioA/vx2ncVtnckQyO5VVdcxPDx8KsCt7vq3X1XVzas7QFW9AngjsC1wbrveTlLnDHCS1nlVtRI4kSHETbmMYcgQ4DnARmux6+cnuUu7Lu5BwMXAqcCfJ9kIIMlDkmwy104YHlz/B0m2aDcU7M8wJLo6XwNeDnyrzV/A0Bv3AODCNdjvWW29+7a6nz+1IMn2VXVWVb0JWMEQ5CR1zmvgJPXiXcBho/kPACe1i/j/k7XrHfsBQ0jaFHhFVf0qyb8wDLOelyQMoWff2XcBVXV1ksMZrj0L8JmqOmkex/8aQ3B8e9vPTUmuBa6oqluAee23Hf9IhiHY64HzR4vfmWSHtv3p/DYsSupYqqaPIEiSJGld5hCqJElSZwxwkiRJnTHASZIkdcYAJ0mS1BkDnCRJUmcMcJIkSZ0xwEmSJHXGACdJktSZ/wevPWi2eI0SygAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# find one-worded, two-worded and three-worded foods\n",
        "one_worded_foods = foods[foods.str.split().apply(len) == 1]\n",
        "two_worded_foods = foods[foods.str.split().apply(len) == 2]\n",
        "three_worded_foods = foods[foods.str.split().apply(len) == 3]\n",
        "\n",
        "# create a bar plot\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.bar([1, 2, 3], [one_worded_foods.size, two_worded_foods.size, three_worded_foods.size])\n",
        "\n",
        "# label the x-axis instances\n",
        "ax.set_xticks([1, 2, 3])\n",
        "ax.set_xticklabels([\"one\", \"two\", \"three\"])\n",
        "\n",
        "# set the title and the xy-axis labels\n",
        "plt.title(\"Number of Words in Food Entities\")\n",
        "plt.xlabel(\"Number of Words\")\n",
        "plt.ylabel(\"Food Entities\")\n",
        "\n",
        "# display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYvUOiJ_jy-z",
        "outputId": "221cc5aa-49a1-4839-8e0f-f47f2e1fab43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1-worded food entities: 1365\n",
            "2-worded food entities: 910\n",
            "3-worded food entities: 758\n"
          ]
        }
      ],
      "source": [
        "# total number of foods\n",
        "total_num_foods = round(one_worded_foods.size / 45 * 100)\n",
        "\n",
        "# shuffle the 2-worded and 3-worded foods since we'll be slicing them\n",
        "two_worded_foods = two_worded_foods.sample(frac=1)\n",
        "three_worded_foods = three_worded_foods.sample(frac=1)\n",
        "\n",
        "# append the foods together \n",
        "foods = one_worded_foods.append(two_worded_foods[:round(total_num_foods * 0.30)]).append(three_worded_foods[:round(total_num_foods * 0.25)])\n",
        "\n",
        "# print the resulting sizes\n",
        "for i in range(3):\n",
        "    print(f\"{i+1}-worded food entities:\", foods[foods.str.split().apply(len) == i + 1].size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SQOf2O42j25j"
      },
      "outputs": [],
      "source": [
        "food_templates = [\n",
        "    \"I ate my {}\",\n",
        "    \"I'm eating a {}\",\n",
        "    \"I just ate a {}\",\n",
        "    \"I only ate the {}\",\n",
        "    \"I'm done eating a {}\",\n",
        "    \"I've already eaten a {}\",\n",
        "    \"I just finished my {}\",\n",
        "    \"When I was having lunch I ate a {}\",\n",
        "    \"I had a {} and a {} today\",\n",
        "    \"I ate a {} and a {} for lunch\",\n",
        "    \"I made a {} and {} for lunch\",\n",
        "    \"I ate {} and {}\",\n",
        "    \"today I ate a {} and a {} for lunch\",\n",
        "    \"I had {} with my husband last night\",\n",
        "    \"I brought you some {} on my birthday\",\n",
        "    \"I made {} for yesterday's dinner\",\n",
        "    \"last night, a {} was sent to me with {}\",\n",
        "    \"I had {} yesterday and I'd like to eat it anyway\",\n",
        "    \"I ate a couple of {} last night\",\n",
        "    \"I had some {} at dinner last night\",\n",
        "    \"Last night, I ordered some {}\",\n",
        "    \"I made a {} last night\",\n",
        "    \"I had a bowl of {} with {} and I wanted to go to the mall today\",\n",
        "    \"I brought a basket of {} for breakfast this morning\",\n",
        "    \"I had a bowl of {}\",\n",
        "    \"I ate a {} with {} in the morning\",\n",
        "    \"I made a bowl of {} for my breakfast\",\n",
        "    \"There's {} for breakfast in the bowl this morning\",\n",
        "    \"This morning, I made a bowl of {}\",\n",
        "    \"I decided to have some {} as a little bonus\",\n",
        "    \"I decided to enjoy some {}\",\n",
        "    \"I've decided to have some {} for dessert\",\n",
        "    \"I had a {}, a {} and {} at home\",\n",
        "    \"I took a {}, {} and {} on the weekend\",\n",
        "    \"I ate a {} with {} and {} just now\",\n",
        "    \"Last night, I ate an {} with {} and {}\",\n",
        "    \"I tasted some {}, {} and {} at the office\",\n",
        "    \"There's a basket of {}, {} and {} that I consumed\",\n",
        "    \"I devoured a {}, {} and {}\",\n",
        "    \"I've already had a bag of {}, {} and {} from the fridge\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xCvi1qkGj5eG"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    (\"I love chicken\", [(8, 13, \"FOOD\")]),\n",
        "    ... \n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3Bxzma54j9Xy"
      },
      "outputs": [],
      "source": [
        "# create dictionaries to store the generated food combinations. Do note that one_food != one_worded_food. one_food == \"barbecue sauce\", one_worded_food == \"sauce\"\n",
        "TRAIN_FOOD_DATA = {\n",
        "    \"one_food\": [],\n",
        "    \"two_foods\": [],\n",
        "    \"three_foods\": []\n",
        "}\n",
        "\n",
        "TEST_FOOD_DATA = {\n",
        "    \"one_food\": [],\n",
        "    \"two_foods\": [],\n",
        "    \"three_foods\": []\n",
        "}\n",
        "\n",
        "# one_food, two_food, and three_food combinations will be limited to 167 sentences\n",
        "FOOD_SENTENCE_LIMIT = 167\n",
        "\n",
        "# helper function for deciding what dictionary and subsequent array to append the food sentence on to\n",
        "def get_food_data(count):\n",
        "    return {\n",
        "        1: TRAIN_FOOD_DATA[\"one_food\"] if len(TRAIN_FOOD_DATA[\"one_food\"]) < FOOD_SENTENCE_LIMIT else TEST_FOOD_DATA[\"one_food\"],\n",
        "        2: TRAIN_FOOD_DATA[\"two_foods\"] if len(TRAIN_FOOD_DATA[\"two_foods\"]) < FOOD_SENTENCE_LIMIT else TEST_FOOD_DATA[\"two_foods\"],\n",
        "        3: TRAIN_FOOD_DATA[\"three_foods\"] if len(TRAIN_FOOD_DATA[\"three_foods\"]) < FOOD_SENTENCE_LIMIT else TEST_FOOD_DATA[\"three_foods\"],\n",
        "    }[count]\n",
        "\n",
        "# the pattern to replace from the template sentences\n",
        "pattern_to_replace = \"{}\"\n",
        "\n",
        "# shuffle the data before starting\n",
        "foods = foods.sample(frac=1)\n",
        "\n",
        "# the count that helps us decide when to break from the for loop\n",
        "food_entity_count = foods.size - 1\n",
        "\n",
        "# start the while loop, ensure we don't get an index out of bounds error\n",
        "while food_entity_count >= 2:\n",
        "    entities = []\n",
        "\n",
        "    # pick a random food template\n",
        "    sentence = food_templates[random.randint(0, len(food_templates) - 1)]\n",
        "\n",
        "    # find out how many braces \"{}\" need to be replaced in the template\n",
        "    matches = re.findall(pattern_to_replace, sentence)\n",
        "\n",
        "    # for each brace, replace with a food entity from the shuffled food data\n",
        "    for match in matches:\n",
        "        food = foods.iloc[food_entity_count]\n",
        "        food_entity_count -= 1\n",
        "\n",
        "        # replace the pattern, but then find the match of the food entity we just inserted\n",
        "        sentence = sentence.replace(match, food, 1)\n",
        "        match_span = re.search(food, sentence).span()\n",
        "\n",
        "        # use that match to find the index positions of the food entity in the sentence, append\n",
        "        entities.append((match_span[0], match_span[1], \"FOOD\"))\n",
        "\n",
        "    # append the sentence and the position of the entities to the correct dictionary and array\n",
        "    get_food_data(len(matches)).append((sentence, {\"entities\": entities}))\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rat7sQswj_Jw",
        "outputId": "6f62864e-1179-44cb-c991-07f3c7b1b7ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "167 one_food sentences: ('This morning, I made a bowl of fuel snacks', {'entities': [(31, 42, 'FOOD')]})\n",
            "167 two_foods sentences: ('I made a traditional white bread and deli rolls for lunch', {'entities': [(9, 32, 'FOOD'), (37, 47, 'FOOD')]})\n",
            "167 three_foods sentences: (\"There's a basket of thin enriched bread, mini buns and cardamom that I consumed\", {'entities': [(20, 39, 'FOOD'), (41, 50, 'FOOD'), (55, 63, 'FOOD')]})\n"
          ]
        }
      ],
      "source": [
        "# create dictionaries to store the generated food combinations. Do note that one_food != one_worded_food. one_food == \"barbecue sauce\", one_worded_food == \"sauce\"\n",
        "TRAIN_FOOD_DATA = {\n",
        "    \"one_food\": [],\n",
        "    \"two_foods\": [],\n",
        "    \"three_foods\": []\n",
        "}\n",
        "\n",
        "TEST_FOOD_DATA = {\n",
        "    \"one_food\": [],\n",
        "    \"two_foods\": [],\n",
        "    \"three_foods\": []\n",
        "}\n",
        "\n",
        "# one_food, two_food, and three_food combinations will be limited to 167 sentences\n",
        "FOOD_SENTENCE_LIMIT = 167\n",
        "\n",
        "# helper function for deciding what dictionary and subsequent array to append the food sentence on to\n",
        "def get_food_data(count):\n",
        "    return {\n",
        "        1: TRAIN_FOOD_DATA[\"one_food\"] if len(TRAIN_FOOD_DATA[\"one_food\"]) < FOOD_SENTENCE_LIMIT else TEST_FOOD_DATA[\"one_food\"],\n",
        "        2: TRAIN_FOOD_DATA[\"two_foods\"] if len(TRAIN_FOOD_DATA[\"two_foods\"]) < FOOD_SENTENCE_LIMIT else TEST_FOOD_DATA[\"two_foods\"],\n",
        "        3: TRAIN_FOOD_DATA[\"three_foods\"] if len(TRAIN_FOOD_DATA[\"three_foods\"]) < FOOD_SENTENCE_LIMIT else TEST_FOOD_DATA[\"three_foods\"],\n",
        "    }[count]\n",
        "\n",
        "# the pattern to replace from the template sentences\n",
        "pattern_to_replace = \"{}\"\n",
        "\n",
        "# shuffle the data before starting\n",
        "foods = foods.sample(frac=1)\n",
        "\n",
        "# the count that helps us decide when to break from the for loop\n",
        "food_entity_count = foods.size - 1\n",
        "\n",
        "# start the while loop, ensure we don't get an index out of bounds error\n",
        "while food_entity_count >= 2:\n",
        "    entities = []\n",
        "\n",
        "    # pick a random food template\n",
        "    sentence = food_templates[random.randint(0, len(food_templates) - 1)]\n",
        "\n",
        "    # find out how many braces \"{}\" need to be replaced in the template\n",
        "    matches = re.findall(pattern_to_replace, sentence)\n",
        "\n",
        "    # for each brace, replace with a food entity from the shuffled food data\n",
        "    for match in matches:\n",
        "        food = foods.iloc[food_entity_count]\n",
        "        food_entity_count -= 1\n",
        "\n",
        "        # replace the pattern, but then find the match of the food entity we just inserted\n",
        "        sentence = sentence.replace(match, food, 1)\n",
        "        match_span = re.search(food, sentence).span()\n",
        "\n",
        "        # use that match to find the index positions of the food entity in the sentence, append\n",
        "        entities.append((match_span[0], match_span[1], \"FOOD\"))\n",
        "\n",
        "    # append the sentence and the position of the entities to the correct dictionary and array\n",
        "    get_food_data(len(matches)).append((sentence, {\"entities\": entities}))\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13s5sSClkD6p",
        "outputId": "53e38851-4c2c-44fd-9fce-7c95671128d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "989 one_food items: ('I had nopalitos with my husband last night', {'entities': [(6, 15, 'FOOD')]})\n",
            "207 two_foods items: ('I ate yogurt creme and habanero pepper jelly', {'entities': [(6, 18, 'FOOD'), (23, 44, 'FOOD')]})\n",
            "209 three_foods items: ('I had a nazook pastry, a drink and flounder fillet at home', {'entities': [(8, 21, 'FOOD'), (25, 30, 'FOOD'), (35, 50, 'FOOD')]})\n"
          ]
        }
      ],
      "source": [
        "for key in TEST_FOOD_DATA:\n",
        "    print(\"{} {} items: {}\".format(len(TEST_FOOD_DATA[key]), key, TEST_FOOD_DATA[key][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "v6lDWzcw_ez7"
      },
      "outputs": [],
      "source": [
        "#  Generating Revision Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "K220c2WU_g-L"
      },
      "outputs": [],
      "source": [
        "# Preparing the revision data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bEfanwJ7oVrv",
        "outputId": "be20e4c9-046a-4d44-a73d-9c6390dcc133"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3a85b14c-a5c2-4a30-99b7-aa5888a85c6f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the Washington of 2016, even when the polic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From photography, illustration and video, to d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a85b14c-a5c2-4a30-99b7-aa5888a85c6f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a85b14c-a5c2-4a30-99b7-aa5888a85c6f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a85b14c-a5c2-4a30-99b7-aa5888a85c6f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             Article\n",
              "0  In the Washington of 2016, even when the polic...\n",
              "1    Donald Trump has used Twitter  —   his prefe...\n",
              "2    Donald Trump is unabashedly praising Russian...\n",
              "3  Updated at 2:50 p. m. ET, Russian President Vl...\n",
              "4  From photography, illustration and video, to d..."
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "npr_df = pd.read_csv(\"/content/drive/MyDrive/INTERNSHIPS/TCR Internship (AI)/Final Project/npr.csv\")\n",
        "\n",
        "# print row and column information\n",
        "npr_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuFhNBV88F7y",
        "outputId": "f8171ec6-acab-4434-ef3e-074091d14436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "# create an nlp object as we'll use this to seperate the sentences and identify existing entities\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XKgHsmzQ8Y0L"
      },
      "outputs": [],
      "source": [
        "revision_texts = []\n",
        "\n",
        "# convert the articles to spacy objects to better identify the sentences. Disabled unneeded components. # takes ~ 4 minutes\n",
        "for doc in nlp.pipe(npr_df[\"Article\"][:6000], batch_size=30, disable=[\"tagger\", \"ner\"]):\n",
        "    for sentence in doc.sents:\n",
        "        if  40 < len(sentence.text) < 80:\n",
        "            # some of the sentences had excessive whitespace in between words, so we're trimming that\n",
        "            revision_texts.append(\" \".join(re.split(\"\\s+\", sentence.text, flags=re.UNICODE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "cA0h-AIE8ifV"
      },
      "outputs": [],
      "source": [
        "revisions = []\n",
        "\n",
        "# Use the existing spaCy model to predict the entities, then append them to revision\n",
        "for doc in nlp.pipe(revision_texts, batch_size=50, disable=[\"tagger\", \"parser\"]):\n",
        "    \n",
        "    # don't append sentences that have no entities\n",
        "    if len(doc.ents) > 0:\n",
        "        revisions.append((doc.text, {\"entities\": [(e.start_char, e.end_char, e.label_) for e in doc.ents]}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "938o6fLY_vWp"
      },
      "outputs": [],
      "source": [
        "# Split train and test revision data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bex1sdzI8jsr",
        "outputId": "37ff8453-553c-4a21-ca13-090abb9c0367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "And in that sense, this year shows little sign of ending on Dec. 31.\n",
            "{'entities': [(19, 28, 'DATE'), (60, 67, 'DATE')]}\n"
          ]
        }
      ],
      "source": [
        "# print an example of the revision sentence\n",
        "print(revisions[0][0])\n",
        "\n",
        "# print an example of the revision data\n",
        "print(revisions[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "JIYFZi7K8mWT"
      },
      "outputs": [],
      "source": [
        "# create arrays to store the revision data\n",
        "TRAIN_REVISION_DATA = []\n",
        "TEST_REVISION_DATA = []\n",
        "\n",
        "# create dictionaries to keep count of the different entities\n",
        "TRAIN_ENTITY_COUNTER = {}\n",
        "TEST_ENTITY_COUNTER = {}\n",
        "\n",
        "# This will help distribute the entities (i.e. we don't want 1000 PERSON entities, but only 80 ORG entities)\n",
        "REVISION_SENTENCE_SOFT_LIMIT = 100\n",
        "\n",
        "# helper function for incrementing the revision counters\n",
        "def increment_revision_counters(entity_counter, entities):\n",
        "    for entity in entities:\n",
        "        label = entity[2]\n",
        "        if label in entity_counter:\n",
        "            entity_counter[label] += 1\n",
        "        else:\n",
        "            entity_counter[label] = 1\n",
        "\n",
        "random.shuffle(revisions)\n",
        "for revision in revisions:\n",
        "    # get the entities from the revision sentence\n",
        "    entities = revision[1][\"entities\"]\n",
        "\n",
        "    # simple hack to make sure spaCy entities don't get too one-sided\n",
        "    should_append_to_train_counter = 0\n",
        "    for _, _, label in entities:\n",
        "        if label in TRAIN_ENTITY_COUNTER and TRAIN_ENTITY_COUNTER[label] > REVISION_SENTENCE_SOFT_LIMIT:\n",
        "            should_append_to_train_counter -= 1\n",
        "        else:\n",
        "            should_append_to_train_counter += 1\n",
        "\n",
        "    # simple switch for deciding whether to append to train data or test data\n",
        "    if should_append_to_train_counter >= 0:\n",
        "        TRAIN_REVISION_DATA.append(revision)\n",
        "        increment_revision_counters(TRAIN_ENTITY_COUNTER, entities)\n",
        "    else:\n",
        "        TEST_REVISION_DATA.append(revision)\n",
        "        increment_revision_counters(TEST_ENTITY_COUNTER, entities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zGheqRJ8rE2",
        "outputId": "497b7855-1312-47b8-bd0a-a257aa509d7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'DATE': 212,\n",
              " 'GPE': 164,\n",
              " 'CARDINAL': 195,\n",
              " 'PERSON': 254,\n",
              " 'LANGUAGE': 85,\n",
              " 'ORG': 192,\n",
              " 'WORK_OF_ART': 103,\n",
              " 'TIME': 108,\n",
              " 'ORDINAL': 110,\n",
              " 'PERCENT': 101,\n",
              " 'NORP': 115,\n",
              " 'LOC': 106,\n",
              " 'MONEY': 102,\n",
              " 'QUANTITY': 101,\n",
              " 'EVENT': 101,\n",
              " 'PRODUCT': 101,\n",
              " 'LAW': 95,\n",
              " 'FAC': 101}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{'DATE': 212,\n",
        " 'GPE': 164,\n",
        " 'CARDINAL': 195,\n",
        " 'PERSON': 254,\n",
        " 'LANGUAGE': 85,\n",
        " 'ORG': 192,\n",
        " 'WORK_OF_ART': 103,\n",
        " 'TIME': 108,\n",
        " 'ORDINAL': 110,\n",
        " 'PERCENT': 101,\n",
        " 'NORP': 115,\n",
        " 'LOC': 106,\n",
        " 'MONEY': 102,\n",
        " 'QUANTITY': 101,\n",
        " 'EVENT': 101,\n",
        " 'PRODUCT': 101,\n",
        " 'LAW': 95,\n",
        " 'FAC': 101}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOMoHqIq89Iy",
        "outputId": "6278f922-a4ec-4c9b-cb18-fdc29885fd64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'PERSON': 14027,\n",
              " 'ORG': 10360,\n",
              " 'DATE': 7153,\n",
              " 'GPE': 5661,\n",
              " 'NORP': 2739,\n",
              " 'CARDINAL': 5397,\n",
              " 'QUANTITY': 171,\n",
              " 'PERCENT': 441,\n",
              " 'TIME': 794,\n",
              " 'FAC': 152,\n",
              " 'LOC': 559,\n",
              " 'ORDINAL': 1151,\n",
              " 'MONEY': 560,\n",
              " 'WORK_OF_ART': 592,\n",
              " 'PRODUCT': 119,\n",
              " 'EVENT': 104,\n",
              " 'LANGUAGE': 24,\n",
              " 'LAW': 12}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{'PERSON': 14027,\n",
        " 'ORG': 10360,\n",
        " 'DATE': 7153,\n",
        " 'GPE': 5661,\n",
        " 'NORP': 2739,\n",
        " 'CARDINAL': 5397,\n",
        " 'QUANTITY': 171,\n",
        " 'PERCENT': 441,\n",
        " 'TIME': 794,\n",
        " 'FAC': 152,\n",
        " 'LOC': 559,\n",
        " 'ORDINAL': 1151,\n",
        " 'MONEY': 560,\n",
        " 'WORK_OF_ART': 592,\n",
        " 'PRODUCT': 119,\n",
        " 'EVENT': 104,\n",
        " 'LANGUAGE': 24,\n",
        " 'LAW': 12}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "rNIqOOqPAByp"
      },
      "outputs": [],
      "source": [
        "# Training the NER Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpdXJrWf8_qY",
        "outputId": "741375e2-d9e8-4068-c9b8-e5b9e7121c0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOOD 501\n",
            "REVISION 1511\n",
            "COMBINED 2012\n"
          ]
        }
      ],
      "source": [
        "# combine the food training data\n",
        "TRAIN_FOOD_DATA_COMBINED = TRAIN_FOOD_DATA[\"one_food\"] + TRAIN_FOOD_DATA[\"two_foods\"] + TRAIN_FOOD_DATA[\"three_foods\"]\n",
        "\n",
        "# print the length of the food training data\n",
        "print(\"FOOD\", len(TRAIN_FOOD_DATA_COMBINED))\n",
        "\n",
        "# print the length of the revision training data\n",
        "print(\"REVISION\", len(TRAIN_REVISION_DATA))\n",
        "\n",
        "# join and print the combined length\n",
        "TRAIN_DATA = TRAIN_REVISION_DATA + TRAIN_FOOD_DATA_COMBINED\n",
        "print(\"COMBINED\", len(TRAIN_DATA))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9m9TOQr9Cqd",
        "outputId": "fe216815-084e-4afe-ac50-2134f7719af2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"There's a basket of applesauce , blast cola and re...\" with entities \"[(20, 31, 'FOOD'), (33, 43, 'FOOD'), (48, 57, 'FOO...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  gold = GoldParse(doc, **gold)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"I ate a salsacuse with marinade  and malt just now\" with entities \"[(8, 17, 'FOOD'), (23, 32, 'FOOD'), (37, 41, 'FOOD...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  gold = GoldParse(doc, **gold)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Last night, I ate an caserecci with toffee  and ch...\" with entities \"[(21, 30, 'FOOD'), (36, 43, 'FOOD'), (48, 58, 'FOO...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  gold = GoldParse(doc, **gold)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Last night, I ate an pretzels with sherbet and bas...\" with entities \"[(21, 29, 'FOOD'), (35, 42, 'FOOD'), (47, 53, 'FOO...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  gold = GoldParse(doc, **gold)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"There's a basket of sticks, dressing  and erythrit...\" with entities \"[(20, 26, 'FOOD'), (28, 37, 'FOOD'), (42, 52, 'FOO...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  gold = GoldParse(doc, **gold)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"I decided to have some peanuts  as a little bonus\" with entities \"[(23, 31, 'FOOD')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  gold = GoldParse(doc, **gold)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"I ate a couple of peppercorn medley  last night\" with entities \"[(18, 36, 'FOOD')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  gold = GoldParse(doc, **gold)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"I took a chicken seasoning grillers, mangoneada an...\" with entities \"[(9, 35, 'FOOD'), (37, 47, 'FOOD'), (52, 59, 'FOOD...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  gold = GoldParse(doc, **gold)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"I ate a squeeze  and a beverage juice for lunch\" with entities \"[(8, 16, 'FOOD'), (23, 37, 'FOOD')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  gold = GoldParse(doc, **gold)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"I devoured a ketchup, pear sauce and lemonade \" with entities \"[(13, 20, 'FOOD'), (22, 32, 'FOOD'), (37, 46, 'FOO...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  gold = GoldParse(doc, **gold)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses (1/30) {'ner': 16141.074182556786}\n",
            "Losses (2/30) {'ner': 15100.640285312864}\n",
            "Losses (3/30) {'ner': 14598.520053639077}\n",
            "Losses (4/30) {'ner': 14681.15871394705}\n",
            "Losses (5/30) {'ner': 14378.04642756842}\n",
            "Losses (6/30) {'ner': 14362.669783049903}\n",
            "Losses (7/30) {'ner': 14231.482577875024}\n",
            "Losses (8/30) {'ner': 14192.62708273041}\n",
            "Losses (9/30) {'ner': 14067.155414268025}\n",
            "Losses (10/30) {'ner': 14210.909468730038}\n",
            "Losses (11/30) {'ner': 13991.059468667256}\n",
            "Losses (12/30) {'ner': 14157.769489249215}\n",
            "Losses (13/30) {'ner': 14007.112681735074}\n",
            "Losses (14/30) {'ner': 13880.934393891861}\n",
            "Losses (15/30) {'ner': 13905.5669521111}\n",
            "Losses (16/30) {'ner': 13844.921431964176}\n",
            "Losses (17/30) {'ner': 13910.961570164072}\n",
            "Losses (18/30) {'ner': 13571.614640180524}\n",
            "Losses (19/30) {'ner': 13773.026946463313}\n",
            "Losses (20/30) {'ner': 13792.831707649748}\n",
            "Losses (21/30) {'ner': 13868.90286010434}\n",
            "Losses (22/30) {'ner': 13901.526074738485}\n",
            "Losses (23/30) {'ner': 14055.503904130659}\n",
            "Losses (24/30) {'ner': 13635.278989832965}\n",
            "Losses (25/30) {'ner': 13711.305551549245}\n",
            "Losses (26/30) {'ner': 13684.120677001207}\n",
            "Losses (27/30) {'ner': 13838.61098082483}\n",
            "Losses (28/30) {'ner': 13783.696352171595}\n",
            "Losses (29/30) {'ner': 13616.626198026875}\n",
            "Losses (30/30) {'ner': 13507.345068634779}\n"
          ]
        }
      ],
      "source": [
        "# add NER to the pipeline and the new label\n",
        "ner = nlp.get_pipe(\"ner\")\n",
        "ner.add_label(\"FOOD\")\n",
        "\n",
        "# get the names of the components we want to disable during training\n",
        "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "\n",
        "# start the training loop, only training NER\n",
        "epochs = 30\n",
        "optimizer = nlp.resume_training()\n",
        "with nlp.disable_pipes(*other_pipes), warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"once\", category=UserWarning, module='spacy')\n",
        "    sizes = compounding(1.0, 4.0, 1.001)\n",
        "    \n",
        "    # batch up the examples using spaCy's minibatc\n",
        "    for epoch in range(epochs):\n",
        "        examples = TRAIN_DATA\n",
        "        random.shuffle(examples)\n",
        "        batches = minibatch(examples, size=sizes)\n",
        "        losses = {}\n",
        "        \n",
        "        for batch in batches:\n",
        "            texts, annotations = zip(*batch)\n",
        "            nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
        "\n",
        "        print(\"Losses ({}/{})\".format(epoch + 1, epochs), losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "kW8YyN11KfYO"
      },
      "outputs": [],
      "source": [
        "# Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "ORPSFRF49G0o",
        "outputId": "310e3145-b01e-4300-a4fc-92eb94949a86"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Apple\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n is looking at buying \\n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    U.K.\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\\n</mark>\\n startup for \\n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    $1 billion\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\\n</mark>\\n</div>'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# display sentence involving original entities\n",
        "spacy.displacy.render(nlp(\"Apple is looking at buying U.K. startup for $1 billion\"), style=\"ent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "WkinuCq79JNQ",
        "outputId": "bb9dae66-bbcd-4885-969d-648b7a370e68"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I ordered \\n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    basmati rice\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\\n</mark>\\n, \\n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    leaf spinach\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\\n</mark>\\n and \\n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    cheese\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\\n</mark>\\n from \\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Tesco\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n yesterday</div>'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# display sentences involving target entity\n",
        "spacy.displacy.render(nlp(\"I had a hamburger and chips for lunch today.\"), style=\"ent\")\n",
        "spacy.displacy.render(nlp(\"I decided to have chocolate ice cream as a little treat for myself.\"), style=\"ent\")\n",
        "spacy.displacy.render(nlp(\"I ordered basmati rice, leaf spinach and cheese from Tesco yesterday\"), style=\"ent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "RI0q2BTvnNg2"
      },
      "outputs": [],
      "source": [
        "#Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "TmD9okgWnGr4",
        "outputId": "a2ed8388-2720-4dc8-9222-6a633a70a888"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Apple\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n is looking at buying \\n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    U.K.\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\\n</mark>\\n startup for \\n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    $1 billion\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\\n</mark>\\n</div>'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# display sentence involving original entities\n",
        "spacy.displacy.render(nlp(\"Apple is looking at buying U.K. startup for $1 billion\"), style=\"ent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "VwwCYK38nZUv",
        "outputId": "4bb0f76a-74d9-4ef9-e0ff-b4d242580d33"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I ordered basmati rice, leaf spinach and cheese from \\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Tesco\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n \\n<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    yesterday\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\\n</mark>\\n</div>'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# display sentences involving target entity\n",
        "spacy.displacy.render(nlp(\"I had a hamburger and chips for lunch today.\"), style=\"ent\")\n",
        "spacy.displacy.render(nlp(\"I decided to have chocolate ice cream as a little treat for myself.\"), style=\"ent\")\n",
        "spacy.displacy.render(nlp(\"I ordered basmati rice, leaf spinach and cheese from Tesco yesterday\"), style=\"ent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "p4AzKI93ne0Q"
      },
      "outputs": [],
      "source": [
        "#Evaluating Food Entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "NLJJcXPlnhtT"
      },
      "outputs": [],
      "source": [
        "# dictionary to hold our evaluation data\n",
        "food_evaluation = {\n",
        "    \"one_food\": {\n",
        "        \"correct\": 0,\n",
        "        \"total\": 0,\n",
        "    },\n",
        "    \"two_foods\": {\n",
        "        \"correct\": 0,\n",
        "        \"total\": 0\n",
        "    },\n",
        "    \"three_foods\": {\n",
        "        \"correct\": 0,\n",
        "        \"total\": 0\n",
        "    }\n",
        "}\n",
        "\n",
        "word_evaluation = {\n",
        "    \"1_worded_foods\": {\n",
        "        \"correct\": 0,\n",
        "        \"total\": 0\n",
        "    },\n",
        "    \"2_worded_foods\": {\n",
        "        \"correct\": 0,\n",
        "        \"total\": 0\n",
        "    },\n",
        "    \"3_worded_foods\": {\n",
        "        \"correct\": 0,\n",
        "        \"total\": 0\n",
        "    }\n",
        "}\n",
        "\n",
        "# loop over data from our test food set (3 keys in total)\n",
        "for key in TEST_FOOD_DATA:\n",
        "    foods = TEST_FOOD_DATA[key]\n",
        "\n",
        "    for food in foods:\n",
        "        # extract the sentence and correct food entities according to our test data\n",
        "        sentence = food[0]\n",
        "        entities = food[1][\"entities\"]\n",
        "\n",
        "        # for each entity, use our updated model to make a prediction on the sentence\n",
        "        for entity in entities:\n",
        "            doc = nlp(sentence)\n",
        "            correct_text = sentence[entity[0]:entity[1]]\n",
        "            n_worded_food =  len(correct_text.split())\n",
        "\n",
        "            # if we find that there's a match for predicted entity and predicted text, increment correct counters\n",
        "            for ent in doc.ents:\n",
        "                if ent.label_ == entity[2] and ent.text == correct_text:\n",
        "                    food_evaluation[key][\"correct\"] += 1\n",
        "                    if n_worded_food > 0:\n",
        "                        word_evaluation[f\"{n_worded_food}_worded_foods\"][\"correct\"] += 1\n",
        "                    \n",
        "                    # this break is important, ensures that we're not double counting on a correct match\n",
        "                    break\n",
        "            \n",
        "            #  increment total counters after each entity loop\n",
        "            food_evaluation[key][\"total\"] += 1\n",
        "            if n_worded_food > 0:\n",
        "                word_evaluation[f\"{n_worded_food}_worded_foods\"][\"total\"] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SQ2fGkMnigJ",
        "outputId": "38dbde24-6452-4e2b-e768-42121de681f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1_worded_foods: 90.91%\n",
            "2_worded_foods: 95.33%\n",
            "3_worded_foods: 92.66%\n",
            "---\n",
            "one_food: 90.50%\n",
            "two_foods: 94.69%\n",
            "three_foods: 94.74%\n",
            "\n",
            "Total: 92.66%\n"
          ]
        }
      ],
      "source": [
        "for key in word_evaluation:\n",
        "    correct = word_evaluation[key][\"correct\"]\n",
        "    total = word_evaluation[key][\"total\"]\n",
        "\n",
        "    print(f\"{key}: {correct / total * 100:.2f}%\")\n",
        "\n",
        "food_total_sum = 0\n",
        "food_correct_sum = 0\n",
        "\n",
        "print(\"---\")\n",
        "for key in food_evaluation:\n",
        "    correct = food_evaluation[key][\"correct\"]\n",
        "    total = food_evaluation[key][\"total\"]\n",
        "    \n",
        "    food_total_sum += total\n",
        "    food_correct_sum += correct\n",
        "\n",
        "    print(f\"{key}: {correct / total * 100:.2f}%\")\n",
        "\n",
        "print(f\"\\nTotal: {food_correct_sum/food_total_sum * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Zj_OhbqZnmTG"
      },
      "outputs": [],
      "source": [
        "#Evaluating Existing Entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Lqc0ZJ2Unkap"
      },
      "outputs": [],
      "source": [
        "# dictionary which will be populated with the entities and result information\n",
        "entity_evaluation = {}\n",
        "\n",
        "# helper function to udpate the entity_evaluation dictionary\n",
        "def update_results(entity, metric):\n",
        "    if entity not in entity_evaluation:\n",
        "        entity_evaluation[entity] = {\"correct\": 0, \"total\": 0}\n",
        "    \n",
        "    entity_evaluation[entity][metric] += 1\n",
        "\n",
        "# same as before, see if entities from test set match what spaCy currently predicts\n",
        "for data in TEST_REVISION_DATA:\n",
        "    sentence = data[0]\n",
        "    entities = data[1][\"entities\"]\n",
        "\n",
        "    for entity in entities:\n",
        "        doc = nlp(sentence)\n",
        "        correct_text = sentence[entity[0]:entity[1]]\n",
        "\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == entity[2] and ent.text == correct_text:\n",
        "                update_results(ent.label_, \"correct\")\n",
        "                break\n",
        "\n",
        "        update_results(entity[2], \"total\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyr-l7b5okVx",
        "outputId": "a4cb7e99-1259-4b83-fba4-78f3cf4cdcc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PERSON | 79.39%\n",
            "ORG | 59.51%\n",
            "DATE | 64.28%\n",
            "GPE | 82.12%\n",
            "ORDINAL | 97.22%\n",
            "TIME | 62.69%\n",
            "CARDINAL | 82.22%\n",
            "MONEY | 85.36%\n",
            "NORP | 83.74%\n",
            "LOC | 66.07%\n",
            "WORK_OF_ART | 61.25%\n",
            "EVENT | 56.73%\n",
            "PERCENT | 90.23%\n",
            "FAC | 66.89%\n",
            "QUANTITY | 70.18%\n",
            "LANGUAGE | 92.31%\n",
            "PRODUCT | 49.58%\n",
            "LAW | 75.00%\n",
            "\n",
            "Overall accuracy: 73.72%\n"
          ]
        }
      ],
      "source": [
        "sum_total = 0\n",
        "sum_correct = 0\n",
        "\n",
        "for entity in entity_evaluation:\n",
        "    total = entity_evaluation[entity][\"total\"]\n",
        "    correct = entity_evaluation[entity][\"correct\"]\n",
        "\n",
        "    sum_total += total\n",
        "    sum_correct += correct\n",
        "    \n",
        "    print(\"{} | {:.2f}%\".format(entity, correct / total * 100))\n",
        "\n",
        "print()\n",
        "print(\"Overall accuracy: {:.2f}%\".format(sum_correct / sum_total * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "NqtjyGTYooLh"
      },
      "outputs": [],
      "source": [
        "# Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "sjmjvX9HomDK"
      },
      "outputs": [],
      "source": [
        "nlp.meta[\"name\"] = \"food_entity_extractor_v2\"\n",
        "nlp.to_disk(\"v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bdzuk5dwo0fp"
      },
      "outputs": [],
      "source": [
        "# The results we arrived at is the following for our FOOD entities:\n",
        "\"\"\"\n",
        "1_worded_foods: 90.91%\n",
        "2_worded_foods: 95.33%\n",
        "3_worded_foods: 92.66%\n",
        "---\n",
        "one_food: 90.50%\n",
        "two_foods: 94.69%\n",
        "three_foods: 94.74%\n",
        "\n",
        "Total: 92.66%\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_VktA_lo8tN"
      },
      "outputs": [],
      "source": [
        "# The results for our existing entities:\n",
        "\"\"\"\n",
        "PERSON | 79.39%\n",
        "ORG | 59.51%\n",
        "DATE | 64.28%\n",
        "GPE | 82.12%\n",
        "ORDINAL | 97.22%\n",
        "TIME | 62.69%\n",
        "CARDINAL | 82.22%\n",
        "MONEY | 85.36%\n",
        "NORP | 83.74%\n",
        "LOC | 66.07%\n",
        "WORK_OF_ART | 61.25%\n",
        "EVENT | 56.73%\n",
        "PERCENT | 90.23%\n",
        "FAC | 66.89%\n",
        "QUANTITY | 70.18%\n",
        "LANGUAGE | 92.31%\n",
        "PRODUCT | 49.58%\n",
        "LAW | 75.00%\n",
        "\n",
        "Overall accuracy: 73.72%\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZYkP8EpPm1u"
      },
      "outputs": [],
      "source": [
        "# nathpulak48002507@gmail.com"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TCR Internship (AI).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
